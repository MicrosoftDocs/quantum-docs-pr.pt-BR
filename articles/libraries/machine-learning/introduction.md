---
title: Biblioteca de aprendizado de máquina Quantum
author: alexeib2
ms.author: alexei.bocharov@microsoft.com
ms.date: 11/22/2019
ms.topic: article
uid: microsoft.quantum.libraries.machine-learning.introduction
ms.openlocfilehash: 4c42612fee3a58e15368677bb2c77a70c5680f45
ms.sourcegitcommit: 6ccea4a2006a47569c4e2c2cb37001e132f17476
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 02/28/2020
ms.locfileid: "77909782"
---
# <a name="introduction-to-quantum-machine-learning"></a><span data-ttu-id="0b2f7-102">Introdução ao Quantum Machine Learning</span><span class="sxs-lookup"><span data-stu-id="0b2f7-102">Introduction to Quantum Machine Learning</span></span>

## <a name="framework-and-goals"></a><span data-ttu-id="0b2f7-103">Estrutura e metas</span><span class="sxs-lookup"><span data-stu-id="0b2f7-103">Framework and goals</span></span>

<span data-ttu-id="0b2f7-104">A codificação de Quantum e o processamento de informações são uma alternativa poderosa para classificadores de Quantum do Machine Learning clássico, em particular, codificar dados em registros Quantum que são concisos em relação ao número de recursos, empregando sistematicamente o Quantum Entanglement como recurso computacional e emprega a medição Quantum para a inferência de classes.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-104">Quantum encoding and processing of information is a powerful alternative to classical machine learning Quantum classifiers, in particular, encode data in quantum registers that are concise relative to the number of features, systematically employ quantum entanglement as computational resource and employ quantum measurement for class inference.</span></span>
<span data-ttu-id="0b2f7-105">O classificador de Quantum centrado em circuito é uma solução Quantum relativamente simples que combina a codificação de dados com um circuito Quantum Entangling/Descomplicando a rápido seguido por medida para inferir rótulos de classe de exemplos de dados.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-105">Circuit centric quantum classifier is a relatively simple quantum solution that combines data encoding with a rapidly entangling/disentangling quantum circuit followed by measurement to infer class labels of data samples.</span></span>
<span data-ttu-id="0b2f7-106">O objetivo é garantir a caracterização clássica e o armazenamento de circuitos de entidades, bem como treinamento híbrido/clássico de os parâmetros de circuito, mesmo para espaços de recursos muito grandes.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-106">The goal is to ensure classical characterization and storage of subject circuits, as well as hybrid quantum/classical training of the circuit parameters even for extremely large feature spaces.</span></span>

## <a name="classifier-architecture"></a><span data-ttu-id="0b2f7-107">Arquitetura do classificador</span><span class="sxs-lookup"><span data-stu-id="0b2f7-107">Classifier architecture</span></span>

<span data-ttu-id="0b2f7-108">A classificação é uma tarefa de aprendizado de máquina supervisionada, em que o objetivo é inferir rótulos de classe $\{y_1, y_2, \ldots, y_d\}$ de determinados exemplos de dados.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-108">Classification is a supervised machine learning task, where the goal is to infer class labels $\{y_1,y_2,\ldots,y_d\}$ of certain data samples.</span></span> <span data-ttu-id="0b2f7-109">O "conjunto de dados de treinamento" é uma coleção de exemplos $ \mathcal{D} =\{(x, y)} $ com rótulos previamente atribuídos conhecidos.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-109">The "training data set" is a collection of samples $\mathcal{D}=\{(x,y)}$ with known pre-assigned labels.</span></span> <span data-ttu-id="0b2f7-110">Aqui $x $ é um exemplo de dados e $y $ é seu rótulo conhecido chamado "rótulo de treinamento".</span><span class="sxs-lookup"><span data-stu-id="0b2f7-110">Here $x$ is a data sample and $y$ is its known label called "training label".</span></span>
<span data-ttu-id="0b2f7-111">De um modo semelhante aos métodos tradicionais, a classificação Quantum consiste em três etapas:</span><span class="sxs-lookup"><span data-stu-id="0b2f7-111">Somewhat similar to traditional methods, quantum classification consists of three steps:</span></span>
- <span data-ttu-id="0b2f7-112">codificação de dados</span><span class="sxs-lookup"><span data-stu-id="0b2f7-112">data encoding</span></span>
- <span data-ttu-id="0b2f7-113">preparação de um estado de classificador</span><span class="sxs-lookup"><span data-stu-id="0b2f7-113">preparation of a classifier state</span></span>
- <span data-ttu-id="0b2f7-114">medida devido à natureza probabilística da medida, essas três etapas devem ser repetidas várias vezes.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-114">measurement Due to the probabilistic nature of the measurement, these three steps must be repeated multiple times.</span></span> <span data-ttu-id="0b2f7-115">A medida pode ser exibida como um equivalente quântico de ativação não linear.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-115">The measurement may be viewed as a quantum equivalent of non-linear activation.</span></span>
<span data-ttu-id="0b2f7-116">A codificação e a computação do estado do classificador são feitas por meio de *circuitos Quantum*.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-116">Both the encoding and the computing of the classifier state are done by means of *quantum circuits*.</span></span> <span data-ttu-id="0b2f7-117">Embora o circuito de codificação seja geralmente controlado por dados e sem parâmetros, o circuito do classificador contém um conjunto suficiente de parâmetros de aprendizado.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-117">While the encoding circuit is usually data-driven and parameter-free, the classifier circuit contains a sufficient set of learnable parameters.</span></span> 

<span data-ttu-id="0b2f7-118">Na solução proposta, o circuito do classificador é composto por rotações de qubit único e rotações controladas de dois qubit.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-118">In the proposed solution the classifier circuit is composed of single-qubit rotations and two-qubit controlled rotations.</span></span> <span data-ttu-id="0b2f7-119">Os parâmetros mais aprendiveis aqui são os ângulos de rotação.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-119">The learnable parameters here are the rotation angles.</span></span> <span data-ttu-id="0b2f7-120">A rotação e as Gates de rotação controlada são conhecidas como *universais* para computação Quantum, o que significa que qualquer matriz de peso unitário pode ser decomposta em um circuito suficientemente longo que consiste em tais Gates.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-120">The rotation and controlled rotation gates are known to be *universal* for quantum computation, which means that any unitary weight matrix can be decomposed into a long enough circuit consisting of such gates.</span></span>

![Perceptron multicamada versus classificador centrado em circuito](~/media/DLvsQCC.png)

<span data-ttu-id="0b2f7-122">Podemos comparar esse modelo com um perceptron de várias camadas para entender melhor a estrutura básica.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-122">We can compare this model to a multilayer perceptron to get a better understanding of the basic structure.</span></span> <span data-ttu-id="0b2f7-123">No Perceptron, a $p de previsão (y | x, \theta) $ é parametrizadas pelo conjunto de pesos $ \theta $ que determinam as funções lineares que conectam as funções de ativação não linear (neurônios).</span><span class="sxs-lookup"><span data-stu-id="0b2f7-123">In the perceptron the predictor $p(y|x, \theta)$ is parametrized by the set of weights $\theta$ that determine the linear functions connecting the non-linear activation functions (neurons).</span></span> <span data-ttu-id="0b2f7-124">Esses parâmetros podem ser treinados para criar o modelo.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-124">These parameters can be trained to create the model.</span></span> <span data-ttu-id="0b2f7-125">Na camada de saída, podemos obter a probabilidade de um exemplo que pertence a uma classe usando funções de ativação não linear, como softmax.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-125">At the output layer we can get the probability of a sample belonging to a class by using non-linear activation functions like softmax.</span></span> <span data-ttu-id="0b2f7-126">No classificador centrado no circuito, o pregnóstico é parametrizadas pelos ângulos de rotação das rotações de qubit e de dois qubit controladas do circuito de modelo.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-126">In the circuit centric classifier the predictor is parametrized by the rotation angles of the single-qubit and two-qubit controlled rotations of the model circuit.</span></span> <span data-ttu-id="0b2f7-127">De maneira semelhante, esses parâmetros podem ser treinados por uma versão híbrida do Quantum/clássico do algoritmo descendente do gradiente.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-127">In a similar fashion, those parameters can be trained by an hybrid quantum/classical version of the gradient descent algorithm.</span></span> <span data-ttu-id="0b2f7-128">Para calcular a saída, em vez de usar funções de ativação não linear, a probabilidade da classe é obtida com a leitura de medidas repetidas em um qubit específico após as rotações controladas.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-128">To calculate the output, instead of using non-linear activation functions, the probability of the class is obtained by reading repeated measurements over a specific qubit after the controlled rotations.</span></span> <span data-ttu-id="0b2f7-129">Para codificar os dados clássicos em um estado Quantum, usamos um circuito de codificação controlável para preparação de estado.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-129">To encode the classical data in a quantum state we use a controllable encoding circuit for state preparation.</span></span>

<span data-ttu-id="0b2f7-130">Nossa arquitetura explora circuitos relativamente superficiais, que, portanto, devem ser *rapidamente entanglingdos* para capturar todas as correlações entre os recursos de dados em todos os intervalos.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-130">Our architecture explores relatively shallow circuits, which therefore must be *rapidly entangling* in order to capture all the correlations between the data features at all ranges.</span></span> <span data-ttu-id="0b2f7-131">Um exemplo do componente de circuito de Entangling rápido mais útil é mostrado na figura abaixo.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-131">An example of the most useful rapidly entangling circuit component is shown on figure below.</span></span> <span data-ttu-id="0b2f7-132">Embora um circuito com essa geometria seja composto por apenas $3 n + 1 $ Gates, a matriz de peso unitário que ele calcula garante uma conversa cruzada significativa entre os recursos de $2 ^ n $.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-132">Even though a circuit with this geometry consists of only $3 n+1$ gates, the unitary weight matrix that it computes ensures significant cross-talk between $2^n$ features.</span></span>

![Entangling rapidamente o circuito Quantum em 5 qubits (com duas camadas cíclicas).](~/media/5-qubit-qccc.png)

<span data-ttu-id="0b2f7-134">O circuito no exemplo acima consiste em 6 Gates de qubit único $ (G_1, \ldots, G_5; G_{16}) $ e 10 2-qubits Gates $ (G_6, \ldots, G_{15}) $.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-134">The circuit in the above example consists of 6 single-qubit gates $(G_1,\ldots,G_5; G_{16})$ and 10 two-qubits gates $(G_6,\ldots,G_{15})$.</span></span> <span data-ttu-id="0b2f7-135">Supondo que cada uma das Gates seja definida com um parâmetro que pode ser aprendiz, temos 16 parâmetros de aprendizado, enquanto a dimensão do espaço Hilbert de 5 qubit é 32.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-135">Assuming that each of the gates is defined with one learnable parameter we have 16 learnable parameters, while the dimension of the 5-qubit Hilbert space is 32.</span></span> <span data-ttu-id="0b2f7-136">Essa geometria de circuito pode ser facilmente generalizada para qualquer registro $n $-qubit, quando $n $ é ímpar, produzindo circuitos com $3 n + 1 $ parâmetros para o espaço de recurso de $2 ^ n $-dimensional.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-136">Such circuit geometry can be easily generalized to any $n$-qubit register, when $n$ is odd, yielding circuits with $3 n+1$ parameters for $2^n$-dimensional feature space.</span></span>

## <a name="classifier-training-as-a-supervised-learning-task"></a><span data-ttu-id="0b2f7-137">Treinamento de classificador como uma tarefa de aprendizado supervisionada</span><span class="sxs-lookup"><span data-stu-id="0b2f7-137">Classifier training as a supervised learning task</span></span>

<span data-ttu-id="0b2f7-138">O treinamento de um modelo classificador envolve encontrar valores ideais de seus parâmetros operacionais, de modo que eles maximizem a probabilidade média de inferir os rótulos de treinamento corretos em todos os exemplos de treinamento.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-138">Training of a classifier model involves finding optimal values of its operational parameters, such that they maximize the average likelihood of inferring the correct training labels across the training samples.</span></span>
<span data-ttu-id="0b2f7-139">Aqui, nos preocupamos com apenas a classificação de dois níveis, ou seja, o caso de $d = $2 e apenas duas classes com os rótulos $y _1, y_2 $.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-139">Here, we concern ourselves with two level classification only, i.e. the case of $d=2$ and only two classes with the labels $y_1,y_2$.</span></span>

> [!NOTE]
> <span data-ttu-id="0b2f7-140">Uma maneira de generalizar nossos métodos para o número arbitrário de classes é substituir qubits por qudits, ou seja, unidades Quantum por Estados de base $d $ e a medida bidirecional com $d medida de $ Way.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-140">A principled way of generalizing our methods to arbitrary number of classes is to replace qubits with qudits, i.e. quantum units with $d$ basis states, and the two-way measurement with $d$-way measurement.</span></span>

### <a name="likelihood-as-the-training-goal"></a><span data-ttu-id="0b2f7-141">Probabilidade da meta de treinamento</span><span class="sxs-lookup"><span data-stu-id="0b2f7-141">Likelihood as the training goal</span></span>

<span data-ttu-id="0b2f7-142">Dado um circuito de Quantum mais aprendente $U (\theta) $, em que $ \theta $ é um vetor de parâmetros e denotando a medida final por $M $, a probabilidade média da inferência de rótulo correta é $ $ \begin{align} \mathcal{L} (\theta) = \frac{1}{| \mathcal{D} |} \left (\ sum_ {(x, y_1) \in\mathcal{D}} P (M = y_1 | U (\theta) x) + \ sum_ {(x, y_2) \in\mathcal{D}} P (M = y_2 | U (\theta) x) \right) \end{align} $ $ em que $P (M = y | z) $ é a probabilidade de medir $y $ no estado Quantum $z $.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-142">Given a learnable quantum circuit $U(\theta)$, where $\theta$ is a vector of parameters, and denoting the final measurement by $M$, the average likelihood of the correct label inference is $$ \begin{align} \mathcal{L}(\theta)=\frac{1}{|\mathcal{D}|} \left( \sum_{(x,y_1)\in\mathcal{D}} P(M=y_1|U(\theta) x) + \sum_{(x,y_2)\in\mathcal{D}} P(M=y_2|U(\theta) x)\right) \end{align} $$ where $P(M=y|z)$ is the probability of measuring $y$ in quantum state $z$.</span></span>
<span data-ttu-id="0b2f7-143">Aqui, é suficiente entender que a função de probabilidade $ \mathcal{L} (\theta) $ é tranqüila em $ \theta $ e seu derivativo em qualquer $ \ theta_j $ pode ser computado, essencialmente, o mesmo protocolo Quantum usado para computar a própria função de probabilidade.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-143">Here, it suffices to understand that the likelihood function $\mathcal{L}(\theta)$ is smooth in $\theta$ and its derivative in any $\theta_j$ can be computed by essentially the same quantum protocol as used for computing the likelihood function itself.</span></span> <span data-ttu-id="0b2f7-144">Isso permite otimizar os descendentes de $ \mathcal{L} (\theta) $ por gradiente.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-144">This allows for optimizing the $\mathcal{L}(\theta)$ by gradient descent.</span></span>

### <a name="classifier-bias-and-training-score"></a><span data-ttu-id="0b2f7-145">Tendência do classificador e pontuação de treinamento</span><span class="sxs-lookup"><span data-stu-id="0b2f7-145">Classifier bias and training score</span></span>

<span data-ttu-id="0b2f7-146">Dado alguns valores intermediários (ou finais) dos parâmetros em $ \theta $, precisamos identificar um único valor real $b $ conhecido como polar de *classificador* para fazer a inferência.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-146">Given some intermediate (or final) values of the parameters in $\theta$, we need to identify a single real value $b$ know as *classifier bias* to do the inference.</span></span> <span data-ttu-id="0b2f7-147">A regra de inferência de rótulo funciona da seguinte maneira:</span><span class="sxs-lookup"><span data-stu-id="0b2f7-147">The label inference rule works as follows:</span></span> 
- <span data-ttu-id="0b2f7-148">Um $x de exemplo $ recebe o rótulo $y _2 $ If e somente se $P (M = y_2 | U (\theta) x) + b > $0.05 (RULE1) (caso contrário, é atribuído o rótulo $y _1 $)</span><span class="sxs-lookup"><span data-stu-id="0b2f7-148">A sample $x$ is assigned label $y_2$ if and only if $P(M=y_2|U(\theta) x) + b > 0.5$  (RULE1) (otherwise it is assigned label $y_1$)</span></span>

<span data-ttu-id="0b2f7-149">Claramente $b $ deve estar no intervalo de $ (-0,5, + 0,5) $ para ser significativo.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-149">Clearly $b$ must be in the interval $(-0.5,+0.5)$ to be meaningful.</span></span>

<span data-ttu-id="0b2f7-150">Um caso de treinamento $ (x, y) na \mathcal{D} $ é considerado uma *classificação* inadequado, considerando a tendência $b $ se o rótulo inferido para $x $ de acordo com RULE1 for realmente diferente do $y $.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-150">A training case $(x,y) \in \mathcal{D}$ is considered a *misclassification* given the bias $b$ if the label inferred for $x$ as per RULE1 is actually different from $y$.</span></span> <span data-ttu-id="0b2f7-151">O número total de classificações incorretas é a *Pontuação de treinamento* do classificador de acordo com o $b de tendência $.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-151">The overall number of misclassifications is the *training score* of the classifier given the bias $b$.</span></span> <span data-ttu-id="0b2f7-152">A tendência de classificação *ideal* $b $ minimiza a pontuação de treinamento.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-152">The *optimal* classifier bias $b$ minimizes the training score.</span></span> <span data-ttu-id="0b2f7-153">É fácil ver que, considerando as estimativas de probabilidade preputadas $\{ P (M = y_2 | U (\theta) x) | (x, \*) \in\mathcal{D} \}$, a tendência de classificador ideal pode ser encontrada pela pesquisa binária no intervalo $ (-0,5, + 0,5) $ fazendo no máximo $ \ log_2 (| \mathcal{D} |) $ Steps.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-153">It is easy to see that, given the precomputed probability estimates $\{ P(M=y_2|U(\theta) x) | (x,\*)\in\mathcal{D} \}$, the optimal classifier bias can be found by binary search in interval $(-0.5,+0.5)$ by making at most $\log_2(|\mathcal{D}|)$ steps.</span></span>

### <a name="reference"></a><span data-ttu-id="0b2f7-154">Referência</span><span class="sxs-lookup"><span data-stu-id="0b2f7-154">Reference</span></span>

<span data-ttu-id="0b2f7-155">Essas informações devem ser suficientes para começar a brincar com o código.</span><span class="sxs-lookup"><span data-stu-id="0b2f7-155">This information should be enough to start playing with the code.</span></span> <span data-ttu-id="0b2f7-156">No entanto, se você quiser saber mais sobre esse modelo, leia a proposta original: [ *' classificadores de Quantum centrado em circuitos ', Maria Schuld, Alex Bocharov, Krysta Svore e Nathan Wiebe*](https://arxiv.org/abs/1804.00633)</span><span class="sxs-lookup"><span data-stu-id="0b2f7-156">However, if you want to learn more about this model, please read the original proposal: [*'Circuit-centric quantum classifiers', Maria Schuld, Alex Bocharov, Krysta Svore and Nathan Wiebe*](https://arxiv.org/abs/1804.00633)</span></span>
